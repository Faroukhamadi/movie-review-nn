{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f609bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a4d81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path() / 'aclImdb' / 'train'\n",
    "test_path = Path() / 'aclImdb' / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07009463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised dataset does not exist\n"
     ]
    }
   ],
   "source": [
    "unsupervised_path = train_path / 'unsup'\n",
    "if os.path.exists(unsupervised_path):\n",
    "    for file in os.listdir(unsupervised_path):\n",
    "        file_path = unsupervised_path / file\n",
    "        os.remove(file_path)\n",
    "    os.rmdir(unsupervised_path)\n",
    "    print('Unsupervised dataset removed')\n",
    "else:\n",
    "    print('Unsupervised dataset does not exist')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb8e8983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_path,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eb625cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to neg\n",
      "Label 1 corresponds to pos\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(train_ds.class_names):\n",
    "    print(\"Label\", i, \"corresponds to\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2ca52b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 10000 files for training.\n",
      "Using 15000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "(test_ds, val_ds) = tf.keras.utils.text_dataset_from_directory(\n",
    "    test_path,\n",
    "    batch_size=32,\n",
    "    validation_split=0.6,\n",
    "    subset='both',\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8b183488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to neg\n",
      "Label 1 corresponds to pos\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(test_ds.class_names):\n",
    "    print(\"Label\", i, \"corresponds to\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bae02e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10_000\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "162c85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bde6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    return tf.strings.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6fff85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = text_ds.map(split_text).reduce(0, lambda x, y: x + tf.size(y)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c080f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5844464"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7de66da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "561c3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(), # this computes the mean embedding for each review :)\n",
    "    tf.keras.layers.Lambda(lambda x: x * tf.sqrt(tf.cast(num_words, tf.float32))), # multiplies mean embedding the sqrt(num_words)\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb58b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e20109d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_ds\u001b[49m,\n\u001b[0;32m      3\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a03bac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a4525449",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews = tfds.load('imdb_reviews', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "be412ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'test': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'unsupervised': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5583f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_new = imdb_reviews['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cb32ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ff35da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_new = imdb_reviews['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c2f5bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val_new = ds_test_new.take(20_000)\n",
    "ds_test_new = ds_test_new.skip(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8f993854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = ds_train_new.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ac7914db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = text_ds.map(split_text).reduce(0, lambda x, y: x + tf.size(y)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0831ed31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5844464"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38333aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_ds = ds_train_new.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "65f237f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Reshape((-1, embedding_dim)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(), # this computes the mean embedding for each review :)\n",
    "    tf.keras.layers.Lambda(lambda x: x * tf.sqrt(tf.cast(num_words, tf.float32))), # multiplies mean embedding the sqrt(num_words)\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c5ae18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f23941a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_new = ds_test_new.map(lambda x, y: (x, tf.expand_dims(y, -1)))\n",
    "ds_train_new = ds_train_new.map(lambda x, y: (x, tf.expand_dims(y, -1)))\n",
    "ds_val_new = ds_val_new.map(lambda x, y: (x, tf.expand_dims(y, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74feae50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16699/25000 [===================>..........] - ETA: 11s - loss: 0.8741 - accuracy: 0.5041"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train_new,\n",
    "    validation_data=ds_val_new,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e7fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97990ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
